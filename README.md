# ğŸ“± SmartPricer â€” End to End Data Science & ML Project

A complete machine learning project that predicts smartphone prices based on technical specifications. Built end-to-end from raw data collection to a deployed web application.

---

## ğŸ§  What I Did â€” End to End

### 1. ğŸ“Š Data Collection & Understanding
- Collected a real-world smartphone dataset with **25+ features** covering brand, processor, camera, battery, display, OS, connectivity and storage specs
- Used `df.info()` to check data types, null counts and memory usage
- Used `df.describe()` to understand statistical distribution of numerical features (min, max, mean, std)
- Used `df.nunique()` to see cardinality of each column â€” helped decide encoding strategy
- Identified that **price** ranged from budget phones under â‚¹5,000 to ultra-premium devices above â‚¹1,50,000

---

### 2. ğŸ§¹ Data Cleaning (Notebook: `Cleaning1.ipynb` & `cleaning2.ipynb`)

#### Initial Data Issues Fixed:
- **Column misalignment** â€” Fixed phones where battery data was in display column, camera data in wrong columns
- **Missing processor info** â€” Manually filled incomplete processor names (e.g., "Octa Core Processor" â†’ full processor specs)
- **Brand standardization** â€” Fixed "OPPO" â†’ "Oppo", extracted company names from model strings
- **Price filtering** â€” Removed phones below â‚¹3,400 (outliers/feature phones)
- **Data type fixes** â€” Converted RAM from MB to GB (512 MB â†’ 0.5 GB), converted 1 TB storage to 1024 GB

#### Feature Extraction from Raw Strings:
- **Processor parsing** â€” Split "Snapdragon 888, Octa Core, 2.84 GHz" into Model, Name, Core, Speed
- **RAM & Memory** â€” Extracted from "12 GB RAM, 256 GB inbuilt" format
- **Battery & Fast Charge** â€” Parsed "5000 mAh Battery with 67W Fast Charging"
- **Display specs** â€” Extracted screen size, resolution, refresh rate from combined strings
- **Camera specs** â€” Split "108MP + 12MP + 5MP Triple Rear & 32MP Front" into separate features
- **Connectivity flags** â€” Extracted 5G, NFC, IR Blaster from SIM column
- **Memory card** â€” Parsed slot type (Dedicated/Hybrid) and capacity from card column
- **OS version** â€” Extracted numeric version from "Android v12" format

#### Final Cleaning Steps:
- **Missing value imputation** â€” Used KNN Imputer for numerical columns
- **Rating conversion** â€” Replaced "No Rating" with NaN, then imputed
- **Boolean conversion** â€” Converted True/False strings to 1/0 integers
- **Processor standardization** â€” Fixed typos, standardized brand names (Apple â†’ Bionic, Mediatek â†’ Dimensity)

---

### 3. ğŸ“ˆ Exploratory Data Analysis (Notebook: `eda_3.ipynb`)

#### Univariate Analysis (Distribution Plots):
- **Price distribution** â€” Histogram + KDE showing right-skewed data (skewness = 6.59), most phones under â‚¹50k
- **Rating distribution** â€” Histogram showing most phones rated 4.0-4.5, some outliers at 0 (No Rating)
- **Brand distribution** â€” Pie chart showing Xiaomi (15%), Samsung (12%), Realme (10%) as top brands
- **Processor brands** â€” Pie chart: Snapdragon (42%), Helio (20%), Dimensity (18%) dominate market
- **RAM distribution** â€” Pie chart: 4GB (30%), 6GB (25%), 8GB (20%) most common
- **Memory distribution** â€” Bar chart: 128GB (40%), 64GB (25%), 256GB (20%) most popular
- **Camera count** â€” Bar chart: Triple camera (50%), Dual (30%), Single (15%)
- **Slot types** â€” Pie chart: Dedicated (45%), Hybrid (15%), Not Supported (40%)

#### Bivariate Analysis (Feature vs Price):
- **Brand vs Price** â€” Bar chart: Apple/Leitz highest (â‚¹1L+), Itel/Lava/Jio lowest (â‚¹5k-10k)
- **Brand vs Rating** â€” Bar chart: Apple/Samsung highest ratings (80+), budget brands lower (70-75)
- **5G vs Price** â€” Point plot: 5G phones average â‚¹60k vs â‚¹25k for non-5G
- **NFC vs Price** â€” Bar chart: NFC phones average â‚¹70k vs â‚¹30k without NFC
- **IR Blaster vs Price** â€” Violin plot: Shows price distribution overlap, slight premium for IR Blaster
- **Processor Model vs Price** â€” Bar chart: Bionic (â‚¹1.2L), Tensor (â‚¹90k) highest; Unisoc (â‚¹8k) lowest
- **Processor Model vs Rating** â€” Bar chart: Snapdragon/Dimensity/Helio rate 80+, Unisoc rates 65
- **Processor Core vs Price/Rating** â€” Dual-axis plot: 6-core (highest price), 8-core (highest rating), 4-core (lowest both)
- **Processor Speed vs Price** â€” Scatter plot: Positive correlation, 3.0+ GHz phones cost â‚¹80k+
- **Screen Size vs Rating** â€” Scatter plot: 6.5-6.7 inch screens have best ratings
- **OS vs Processor Core** â€” Stacked bar: Android uses 8-core, iOS uses 6-core predominantly

#### Correlation Analysis:
- **Heatmap** â€” Full correlation matrix of all numerical features
- **Top correlations with price**: RAM (0.65) > Processor Speed (0.58) > Back Camera MP (0.52) > Screen Size (0.45) > Refresh Rate (0.40)
- **Weak correlations**: Battery (0.15), os_version (0.12), capacity_gb (0.08)

---

### 4. âš™ï¸ Feature Engineering

This was the most important and time-consuming step â€” transforming raw messy columns into clean, model-ready features.

#### Camera Feature Extraction
Raw camera data was a single messy string like `"108MP + 12MP + 5MP, 32MP"`. Parsed and split into:
- `Back_Camera_MP` â€” main rear camera megapixels
- `Num_Back_Cam` â€” total number of rear cameras
- `Front_CAM_MP` â€” front camera megapixels
- `Num_Front_Cam` â€” number of front cameras

#### Processor Feature Extraction
Raw processor name like `"Snapdragon 888 Octa-core 2.84GHz"` was parsed into:
- `Processor_Model` â€” brand family (Snapdragon, Dimensity, Bionic, Exynos, Kirin, Tensor, Helio, Unisoc)
- `Processor_Core` â€” number of cores (4, 6, 8)
- `Processor_Speed` â€” clock speed in GHz

#### Connectivity Binary Flags
Extracted boolean features from spec strings:
- `Has_5G` â€” 1 if phone supports 5G, else 0
- `Has_NFC` â€” 1 if phone has NFC, else 0
- `Has_IR_Blaster` â€” 1 if phone has IR blaster, else 0

#### Storage Features
- `card_support` â€” 1 if expandable storage supported, else 0
- `slot_type` â€” type of slot: `Dedicated`, `Hybrid`, or `Not Slot`
- `capacity_gb` â€” maximum expandable storage capacity in GB

#### Fast Charging
- `Fast_Charge` â€” charging wattage extracted from spec (0 if no fast charge)

#### Final Feature Set
After all engineering, the model was trained on **24 clean, meaningful features** â€” each directly interpretable and relevant to price prediction.

---

### 5. ğŸ”„ Preprocessing Pipeline
- Built a **ColumnTransformer** (`ct`) to handle both categorical and numerical features in one clean pipeline:
  - **Categorical columns** â†’ Encoded using OrdinalEncoder / LabelEncoder
  - **Numerical columns** â†’ Scaled using StandardScaler / MinMaxScaler
- Saved the transformer as `ct.pkl` using `pickle` â€” critical for deployment so the exact same transformations are applied at prediction time as during training

---

### 6. ğŸ¤– Model Training (Notebook: `eda_3.ipynb`)

#### Model Comparison:
Tested multiple algorithms on 80/20 train/test split:
- **Linear Regression**: RÂ² = 0.76
- **Random Forest**: RÂ² = 0.85
- **Gradient Boosting**: RÂ² = 0.79
- **XGBoost**: RÂ² = 0.90 âœ… (Best performance)
- **LightGBM**: RÂ² = 0.88
- **Ridge/ElasticNet**: RÂ² = 0.76-0.79

#### Final Model (XGBoost):
- **Parameters**: n_estimators=260, learning_rate=0.05, max_depth=5, subsample=0.8
- **Performance**: RÂ² = 0.903, RMSE = 7,724, MSE = 59,656,463
- **Preprocessing**: StandardScaler applied to all features before training
- **Saved artifacts**: `model.pkl` (trained XGBoost) and `ct.pkl` (ColumnTransformer)

---

### 7. ğŸš€ Deployment with FastAPI
- Built a production REST API using **FastAPI**
- `/predict` endpoint â€” accepts all 24 phone specs as JSON, runs `ct.transform()` + `model.predict()`, returns predicted price in INR
- `/processor-data` endpoint â€” serves processor lookup from real dataset for the frontend drill-down UI
- `/` route â€” serves `index.html` directly so no separate web server is needed
- CORS middleware enabled for cross-origin requests

---

### 8. ğŸŒ Frontend (HTML/CSS/JS)
- Built a clean, dark-themed UI in plain HTML, CSS and JavaScript â€” no framework needed
- **2-level processor drill-down**: pick brand (Snapdragon, Dimensity etc.) â†’ pick exact model â†’ Core & Speed auto-fill automatically
- **Toggle switches** for boolean features (5G, NFC, IR Blaster, Fast Charge, Memory Card)
- **Dropdowns** populated with exact unique values from the training dataset to prevent any mismatch with the model
- Price displayed in **PKR** (converted from INR on the frontend using exchange rate of 1 INR â‰ˆ 3.5 PKR)
- Sends form data to FastAPI backend via `fetch()` API call
- Responsive design with smooth animations and loading states

---

## ğŸ—‚ï¸ Project Structure

```
SmartPricer/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py          â† FastAPI backend (API + serves frontend)
â”‚   â”œâ”€â”€ index.html       â† Frontend UI (HTML/CSS/JS)
â”‚   â”œâ”€â”€ requirements.txt â† Python dependencies
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ data.csv     â† Final cleaned dataset (used for processor lookup)
â”‚   â””â”€â”€ model/
â”‚       â”œâ”€â”€ model.pkl    â† Trained XGBoost model
â”‚       â””â”€â”€ ct.pkl       â† Fitted ColumnTransformer
â”œâ”€â”€ data/                â† Raw & intermediate data files
â”‚   â”œâ”€â”€ Smart-phone.xlsx
â”‚   â”œâ”€â”€ Clean1_Smart_phone.csv
â”‚   â””â”€â”€ Clean2_Smart_Phones.csv
â”œâ”€â”€ notebook/            â† Jupyter notebooks (EDA, cleaning, training)
â”‚   â”œâ”€â”€ Cleaning1.ipynb
â”‚   â”œâ”€â”€ cleaning2.ipynb
â”‚   â””â”€â”€ eda_3.ipynb
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup & Run

### Prerequisites
- Python 3.8 or higher
- pip package manager

### 1. Install dependencies
```bash
cd app
pip install -r requirements.txt
```

**Note:** If you're training the model yourself, you'll also need:
- `xgboost` for the ML model
- `matplotlib` and `seaborn` for EDA visualizations
- `jupyter` for running notebooks

### 2. Run the server
```bash
cd app
uvicorn main:app --reload
```

The `--reload` flag enables auto-reload on code changes (useful for development).

### 3. Open in browser
```
http://localhost:8000
```

### 4. API Documentation
Interactive API docs (Swagger UI) available at:
```
http://localhost:8000/docs
```

Alternative ReDoc documentation:
```
http://localhost:8000/redoc
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Tool |
|---|---|
| Language | Python 3.8+ |
| Data Analysis | Pandas, NumPy |
| Visualization | Matplotlib, Seaborn |
| ML Model | XGBoost Regressor |
| Preprocessing | Scikit-learn (ColumnTransformer, StandardScaler, OrdinalEncoder) |
| Backend API | FastAPI, Uvicorn |
| API Validation | Pydantic |
| Frontend | HTML5, CSS3, Vanilla JavaScript |
| Data Serialization | Pickle (for model persistence) |

---

## ğŸ““ Notebooks Overview

The project includes three Jupyter notebooks documenting the complete workflow:

1. **`Cleaning1.ipynb`** â€” Initial data cleaning
   - Fixed column misalignments
   - Fixed wrong data placements
   - Standardized brand names
   - Removed outliers and feature phones

2. **`cleaning2.ipynb`** â€” Feature engineering
   - Extracted 24 features from raw text columns
   - Parsed processor, camera, battery, display specs
   - Created connectivity flags (5G, NFC, IR Blaster)
   - Handled missing values with KNN imputation

3. **`eda_3.ipynb`** â€” Analysis and modeling
   - Univariate and bivariate visualizations
   - Correlation analysis with heatmaps
   - Model comparison and selection
   - Final XGBoost training and evaluation

---

## ğŸ”‘ Key Learnings

- Real-world data is messy â€” **data cleaning and feature engineering took more time than model training**
- Always save the **ColumnTransformer alongside the model** â€” without `ct.pkl`, deployment predictions will be completely wrong
- **EDA is not optional** â€” visualizations revealed that RAM and processor speed matter far more than battery for pricing
- **FastAPI** makes it easy to serve ML models as production-ready REST APIs in just a few lines
- How to connect a plain HTML frontend to a Python backend using `fetch()` with no framework needed
- Feature engineering from raw strings (camera specs, processor names) dramatically improved model quality
